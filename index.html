<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Abhijay Ghildyal</title>

  <meta name="author" content="Abhijay Ghildyal">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody style="padding:0px">
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;vertical-align:top;">
                  <p style="text-align:center">
                    <name>ABHIJAY GHILDYAL</name>
                  </p>
                  <p style="padding:2.5%;width:30%;max-width:30%;margin-left: auto; margin-right: auto;">
                    <a href="images/profile_pic2.jpg"><img style="width:100%;max-width:100%;border-radius: 25px;"
                        alt="profile photo" src="images/profile_pic2.jpg" class="hoverZoomLink"></a>
                  </p>
                  <p style="text-align: justify">
                    I am a 6th-year CS Ph.D. student in the Computer Graphics and Vision Lab at Portland State
                    University. I'm fortunate to be advised by <a href="http://web.cecs.pdx.edu/~fliu/">Dr. Feng
                      Liu</a>.
                  </p>
                  <p style="text-align: justify">
                    My research interests lie broadly in computational visual perception, novel view
                    synthesis, machine learning safety, adversarial robustness, robotics, and precision agriculture.
                  </p>
                  <p style="text-align: justify">
                    In the summer of 2023, I was an intern in the <a
                      href="https://www.amazon.science/tag/3d-modeling-imaging">Imaging Science</a> team at Amazon.
                  </p>
                  <p style="text-align:justify">
                  <div style="font-family: 'Roboto Mono Regular';background-color:yellow;">I am currently seeking job opportunities as a
                    Computer Vision Research Scientist/Engineer.</div>
                  </p>
                  To learn more or connect with me, here are my links:
                  <ul>
                    <li> <a href="mailto:abhijay@pdx.edu">Email</a> </li>
                    <li> <a
                        href="https://drive.google.com/file/d/1Yz1u4DeyJUobZlZ9l5--ngsEWebpRCca/view?usp=sharing">CV</a>
                    </li>
                    <li> <a href="https://github.com/abhijay9/">Github</a> </li>
                    <li> <a href="https://www.linkedin.com/in/abhijay-ghildyal/">Linkedin</a> </li>
                    <li> <a href="https://twitter.com/abhijay_9/">Twitter</a> </li>
                    <li> <a href="https://scholar.google.com/citations?user=8Sdd57YAAAAJ&hl=en">Google Scholar</a> </li>
                  </ul>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <br />

          <summary>
            <heading>Research</heading>
          </summary>
          <br>

          <table style="width:100%;">
            <tbody>


              <tr>
                <!-- <td style="width:50%;vertical-align:middle;text-align:center;">

                  <img src='images/lar_iqa.png' width="80%" style="margin-top:20px;">

                </td> -->
              </tr>
              <tr>
                <td style="width:100%; vertical-align:middle; border-bottom: 2px solid black;">
                  <papertitle>Foundation Models Boost Low-Level Perceptual Similarity Metrics
                  </papertitle>
                  <br>
                  <u>Abhijay Ghildyal</u>,
                  <a href="https://scholar.google.co.uk/citations?user=69Xj8bEAAAAJ">Nabajeet Barman</a>,
                  <a href="https://scholar.google.com/citations?user=cx3WgewAAAAJ">Saman Zadtootaghaj</a>
                  <br>
                  Under Review
                  <br>
                  <a href="https://arxiv.org/abs/2409.07650">arXiv</a>
                  &nbsp/&nbsp
                  <a href="https://github.com/abhijay9/ZS-IQA">code</a>
                  &nbsp/&nbsp
                  <a href="data/zspsm.bib">bibtex</a>
                  <p></p>
                  <p style="text-align: justify">
                    Previous perceptual similarity models using foundation models focus on the final layer or embedding.
                    In contrast, this work investigates the use of intermediate features, which remain largely
                    unexplored in low-level perceptual similarity metrics. We show that intermediate features are more
                    effective and, by applying feature distance measures without requiring training (zero-shot), can
                    outperform existing metrics.
                  </p>
                </td>
              </tr>

              <p></p>

              <tr>
                <td style="width:50%;vertical-align:middle;text-align:center;">

                  <img src='images/lar_iqa.png' width="80%" style="margin-top:20px;">

                </td>
              </tr>
              <tr>
                <td style="width:100%; vertical-align:middle; border-bottom: 2px solid black;">
                  <papertitle>LAR-IQA: A Lightweight, Accurate, and Robust No-Reference Image Quality Assessment Model
                  </papertitle>
                  <br>
                  <a href="https://github.com/nasimjamshidi">Nasim J. Avanaki</a>,
                  <u>Abhijay Ghildyal</u>,
                  <a href="https://scholar.google.co.uk/citations?user=69Xj8bEAAAAJ">Nabajeet Barman</a>,
                  <a href="https://scholar.google.com/citations?user=cx3WgewAAAAJ">Saman Zadtootaghaj</a>
                  <br>
                  Advances in Image Manipulation Workshop at European Conference on Computer Vision (ECCV), 2024
                  <br>
                  <a href="https://arxiv.org/abs/2408.17057">arXiv</a>
                  &nbsp/&nbsp
                  <a href="https://github.com/nasimjamshidi/LAR-IQA">code</a>
                  &nbsp/&nbsp
                  <a href="data/lariqa.bib">bibtex</a>
                  <p></p>
                  <p style="text-align: justify">
                    We developed a lightweight No-Reference Image Quality Assessment (NR-IQA) model. It uses a
                    dual-branch architecture, with one branch trained on synthetically distorted images and the other on
                    authentically distorted images, improving generalizability across distortion types.
                  </p>
                </td>
              </tr>

              <p></p>

              <tr>
                <td style="width:50%;vertical-align:middle;text-align: center;">

                  <img src='images/lpips_pgd.gif' width="40%" style="margin-top:20px;">

                </td>
              </tr>
              <!-- <tr style="background-color:#aaaaaa4c"> -->
              <tr>
                <td style="width:100%; vertical-align:middle; border-bottom: 2px solid black;">
                  <papertitle>Attacking Perceptual Similarity Metrics</papertitle>
                  <br>
                  <u>Abhijay Ghildyal</u>,
                  <a href="http://web.cecs.pdx.edu/~fliu/">Feng Liu</a> <br>
                  Transactions on Machine Learning Research (TMLR), 2023
                  <br>
                  <span style="color: red;"> Featured Certification </span> <span>(Spotlight ðŸŒŸ or top ~0.01% of the
                    accepted papers)</span>
                  <br>
                  <a href="https://arxiv.org/abs/2305.08840">arXiv</a>
                  &nbsp/&nbsp
                  <a href="https://github.com/abhijay9/attacking_perceptual_similarity_metrics">code</a>
                  &nbsp/&nbsp
                  <a href="https://openreview.net/forum?id=r9vGSpbbRO">OpenReview</a>
                  &nbsp/&nbsp
                  <a href="data/attackpsm.bib">bibtex</a>
                  <p></p>
                  <p style="text-align: justify">
                    In this study, we systematically examine the robustness of both traditional and learned perceptual
                    similarity metrics to imperceptible adversarial perturbations.
                  </p>
                </td>
              </tr>

              <p></p>

              <tr>
                <td style="width:50%;vertical-align:middle;text-align: center;">

                  <img src='images/teaser_vfips.png' width="50%" style="margin-top:20px;">

                </td>
              </tr>
              <tr>
                <td style="width:100%; vertical-align:middle; border-bottom: 2px solid black;">
                  <papertitle>A Perceptual Quality Metric for Video Frame Interpolation</papertitle>
                  <br>
                  <a href="https://hqqxyy.github.io/">Qiqi Hou</a>,
                  <u>Abhijay Ghildyal</u>,
                  <a href="http://web.cecs.pdx.edu/~fliu/">Feng Liu</a> <br>
                  European Conference on Computer Vision (ECCV), 2022
                  <br>
                  <a href="https://arxiv.org/abs/2210.01879">arXiv</a>
                  &nbsp/&nbsp
                  <a href="https://github.com/hqqxyy/VFIPS">code</a>
                  &nbsp/&nbsp
                  <a href="https://web.cecs.pdx.edu/~qiqi2/files/papers/vfips/Video_Demo_Final.mp4">video</a>
                  &nbsp/&nbsp
                  <a href="data/vfips.bib">bibtex</a>
                  <p></p>
                  <p style="text-align: justify">
                    We developed a perceptual quality metric for measuring video frame interpolation results. Our method
                    learns perceptual features directly from videos instead of individual frames.
                  </p>
                </td>
              </tr>

              <p></p>

              <tr>
                <td style="width:50%;vertical-align:middle;text-align: center;">

                  <img src='images/stlpips_teaser.gif' width="50%" style="margin-top:20px;">

                </td>
              </tr>
              <tr>
                <!-- <td style="width:100%; vertical-align:middle; border-bottom: 2px solid black;"> -->
                  <td>
                  <papertitle>Shift-tolerant Perceptual Similarity Metric</papertitle>
                  <br>
                  <u>Abhijay Ghildyal</u>,
                  <a href="http://web.cecs.pdx.edu/~fliu/">Feng Liu</a> <br>
                  European Conference on Computer Vision (ECCV), 2022
                  <br>
                  <a href="https://arxiv.org/abs/2207.13686">arXiv</a>
                  &nbsp/&nbsp
                  <a href="https://github.com/abhijay9/ShiftTolerant-LPIPS">code</a>
                  &nbsp/&nbsp
                  <a href="https://www.youtube.com/watch?v=F6C5VQJGIrM">video</a>
                  &nbsp/&nbsp
                  <a href="https://github.com/chaofengc/IQA-PyTorch/pull/93">IQA-PyTorch</a>
                  <!-- &nbsp/&nbsp    
	      <a href=""></a> -->
                  &nbsp/&nbsp
                  <a href="data/st-lpips.bib">bibtex</a>
                  <p></p>
                  <p style="text-align: justify">
                    We investigated a broad range of neural network elements and developed a robust perceptual
                    similarity metric. Our shift-tolerant perceptual similarity metric (ST-LPIPS) is consistent with
                    human perception and is less susceptible to imperceptible misalignments between two images than
                    existing metrics.
                  </p>
                </td>
              </tr>

            </tbody>
          </table>


          <p>
            <br />

            <summary>
              <heading>Experience</heading>
            </summary>


          <table>
            <tr>
              <td width="100%" valign="middle">
                <dl>
                  <ul>
                    <li>
                      <dt>
                        Amazon
                        <br />
                        <a href="https://www.amazon.science/tag/3d-modeling-imaging">Team: Imaging Science</a>
                      </dt>
                      <dd>
                        <i>Applied Scientist Intern</i> <span style="float:right">Jun'23 - Oct'23 (4 months)</span>
                      </dd>
                    </li>

                    <p>
                      <li>

                        <dt>
                          <a href="https://www.cambiahealth.com/">Cambia Health Solutions</a>
                        </dt>
                        <dd>
                          <i>Deep Learning Intern</i> <span style="float:right">May'19 - Jul'19 (3 months)</span>
                        </dd>
                      </li>

                    <p>

                      <li>
                        <dt>
                          Washington State University
                          <br />
                          <a href="https://cpaas.wsu.edu/">Lab: Center for Precision and Automated <br/> Agricultural
                            Systems</a>
                        </dt>
                        <dd>
                          <i>Graduate Research Assistant</i> <span style="float:right">Dec'18 - Feb'19 (3 months)</span>
                        </dd>
                        <dd>
                          Advised by <a href="https://labs.wsu.edu/karkee-ag-robotics/">Dr. Manoj Karkee</a>
                        </dd>
                      </li>

                    <p>
                      <li>
                        <dt>
                          <a href="https://www.quantela.com/">Quantela Inc.</a>
                        </dt>
                        <dd>
                          <i>Data Scientist</i> <span style="float:right">Nov'17 - Aug'18 (10 months)</span>
                        </dd>
                      </li>

                    <p>
                      <li>
                        <dt>
                          <a href="https://www.mu-sigma.com/">Mu Sigma Inc.</a>
                          <br />
                          Team: Innovation and Development Labs
                        </dt>
                        <dd>
                          <i>Data Science Research Analyst</i> &nbsp &nbsp &nbsp &nbsp &nbsp <span
                            style="float:right">Oct'15 -
                            Nov'17 (2 years)</span>
                        </dd>
                      </li>

                    <p>

                      <li>
                        <dt>
                          <a href="https://www.iitb.ac.in/">Indian Institute of Technology Bombay</a>
                        </dt>
                        <dd>
                          <i>Research Intern</i> <span style="float:right">Jun'15 - Oct'15 (6 months)</span>
                        </dd>
                        <dd>
                          Advised by <a href="https://www.cse.iitb.ac.in/~ganesh/">Dr. Ganesh Ramakrishnan</a>
                        </dd>
                      </li>
                  </ul>
                </dl>
              </td>
            </tr>
          </table>


          <p>


            <summary>
              <heading>Services</heading>
            </summary>
          <table>
            <tr>
              <td width="100%" valign="middle">
                <dl>
                  <dt>Conference and Journal Reviewer</dt>
                  <dd>ACMMM (2022)</dd>
                  <dd>TMLR (2023)</dd>
                  <dd>WACV (2024, 2025)</dd>
                  <dd>TPAMI (2024)</dd>
                  <dd>ECCV (2024)</dd>
                  <dd>AAAI (2025)</dd>
                  <dt>Workshop Reviewer</dt>
                  <dd>WiCV (CVPR 2023, CVPR 2024, ECCV 2024) </dd>
                  <dd>AI4VA: AI for Visual Arts Workshop and Challenges (ECCV 2024) </dd>
                  <dd>Out Of Distribution Generalization in Computer Vision (ECCV 2024) </dd>
                </dl>
              </td>
            </tr>
          </table>


          <p>

            <summary>
              <heading>Awards</heading>
            </summary>

          <table>
            <tr>
              <td width="100%" valign="middle">
                <ul>
                  <li>Richard Kieburtz Memorial Graduate Fellowship</li>
                </ul>
              </td>
            </tr>
          </table>

          <p>

            <summary>
              <heading>Teaching</heading>
            </summary>
          <table>
            <tr>
              <td width="100%" valign="middle">
                <dl>
                  <dt>Teaching Assistant</dt>
                  <dd>CS 441/541 Artificial Intelligence (Fall'19,Winter'20)</dd>
                  <dd>CS 445/545 Machine Learning (Spring'21)</dd>
                  <dd>CS 447/547 Computer Graphics (Fall'21)</dd>
                </dl>
              </td>
            </tr>
          </table>

          <p>
            <br/>

          </p>
          <p style="width:100%;">
            <a class="twitter-timeline" href="https://twitter.com/abhijay_9?ref_src=twsrc%5Etfw">Tweets by abhijay_9</a>
            <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
          </p>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:center;font-size:small;">
                    Design and source code from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's
                      website</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>